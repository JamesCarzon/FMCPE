{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f7c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from lampe.inference import FMPE, FMPELoss\n",
    "from lampe.utils import GDStep\n",
    "import matplotlib\n",
    "from tqdm import trange\n",
    "\n",
    "matplotlib.use(\"Agg\")  # use the “Agg” backend—no X server needed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Computer Modern\"],\n",
    "        \"axes.titlesize\": 14,\n",
    "        \"axes.labelsize\": 12,\n",
    "        \"xtick.labelsize\": 10,\n",
    "        \"ytick.labelsize\": 10,\n",
    "        \"legend.fontsize\": 10,\n",
    "        \"text.usetex\": True,\n",
    "    }\n",
    ")\n",
    "from flow_matching.torch_flow import FlowMatching\n",
    "from baselines.trainers import train_flow_matching\n",
    "from simulator import get_simulator\n",
    "from simulator.base import generate_calibration_dataset as generate_dataset\n",
    "from utils.misc import loader_from_tensor, rescale, train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Found device: {device}\")\n",
    "task_params = {\n",
    "    \"theta_dim\": 2,\n",
    "    \"obs_dim\": 2,\n",
    "    \"prior_var_scale\": 1,\n",
    "    \"likelihood_var_scale\": 1,\n",
    "    \"noisy_var_scale\": 1,\n",
    "    \"seed\": 0,\n",
    "}\n",
    "simulator = get_simulator(\"pure_gaussian\", **task_params)\n",
    "num_samples = 25000\n",
    "thetad, xd, yd = generate_dataset(\n",
    "    simulator,\n",
    "    num_samples,\n",
    "    generation=\"transitive\",\n",
    ")\n",
    "thetad = thetad.reshape(-1, thetad.shape[-1])\n",
    "theta_o, xd_o, yd_o = generate_dataset(simulator, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ad49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7812a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_matching = FlowMatching(\n",
    "    conditional=True,\n",
    "    probability_path=\"ot\",\n",
    "    prior=\"uniform\",\n",
    "    base_dist=\"gaussian\",\n",
    "    dim=xd.shape[1],\n",
    "    drift={\"architecture\": \"resmlp\", \"hidden_dim\": [64, 64]},\n",
    ")\n",
    "flow_matching.to(device)\n",
    "model_path = Path(\"scripts/models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "noise = torch.randn_like(xd)\n",
    "logname = \"_pure_gaussian_x_no_cond\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = False\n",
    "if Path(model_path / f\"flow_matching{logname}.pth\").exists() and not retrain:\n",
    "    flow_matching.load_state_dict(torch.load(model_path / f\"flow_matching{logname}.pth\"))\n",
    "    flow_matching.to(device)\n",
    "\n",
    "else:\n",
    "    flow_matching = train_flow_matching(\n",
    "        flow_matching,\n",
    "        xd,\n",
    "        noise,\n",
    "        device,\n",
    "        None,\n",
    "        model_path,\n",
    "        logname=logname,\n",
    "        epochs=300,\n",
    "        batch_size=256,\n",
    "        lr=1e-4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d39907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_o_scaled = rescale(xd_o, scales[\"x_mean\"], scales[\"x_std\"])\n",
    "savedir = Path(\"figures/scripts/pure_gaussian_baselines\")\n",
    "savedir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ee923",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_matching_conditional = FlowMatching(\n",
    "    conditional=True,\n",
    "    probability_path=\"ot2\",\n",
    "    # prior=\"power\",\n",
    "    prior=\"uniform\",\n",
    "    base_dist=\"gaussian\",\n",
    "    # base_dist=\"none\",\n",
    "    dim=xd.shape[1],\n",
    "    # prior_params={\"rate\": 2},\n",
    "    drift={\"architecture\": \"attention_mlp\", \"hidden_dim\": [64, 64, 64, 64, 64]},\n",
    ")\n",
    "flow_matching.to(device)\n",
    "model_path = Path(\"scripts/models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "noise = torch.randn_like(xd)\n",
    "logname = \"_pure_gaussian_x_cond\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71cff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = True\n",
    "if Path(model_path / f\"flow_matching{logname}.pth\").exists() and not retrain:\n",
    "    flow_matching_conditional.load_state_dict(\n",
    "        torch.load(model_path / f\"flow_matching{logname}.pth\")\n",
    "    )\n",
    "    flow_matching_conditional.to(device)\n",
    "else:\n",
    "    flow_matching_conditional = train_flow_matching(\n",
    "        flow_matching_conditional,\n",
    "        xd,\n",
    "        yd,\n",
    "        device,\n",
    "        None,\n",
    "        model_path,\n",
    "        logname=logname,\n",
    "        epochs=300,\n",
    "        batch_size=256,\n",
    "        lr=1e-3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e583031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train FMPE for reference\n",
    "estimator = FMPE(2, 2, hidden_features=[64] * 5, activation=torch.nn.ELU)\n",
    "loss = FMPELoss(estimator)\n",
    "optimizer = torch.optim.Adam(estimator.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 128)\n",
    "step = GDStep(optimizer, clip=1.0)  # gradient descent step with gradient clipping\n",
    "\n",
    "estimator.train()\n",
    "loader, _ = train_val_split(xd, yd, batch_size=256, train_size=0.8)\n",
    "\n",
    "for epoch in (bar := trange(128, unit=\"epoch\")):\n",
    "    losses = []\n",
    "\n",
    "    for theta, x in loader:  # 256 batches per epoch\n",
    "        losses.append(step(loss(theta, x)))\n",
    "\n",
    "    bar.set_postfix(loss=torch.stack(losses).mean().item())\n",
    "\n",
    "with torch.no_grad():\n",
    "    samples = estimator.flow(yd_o[:4].to(device)).sample((1000,)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae670cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = flow_matching_conditional.sample_source(yd_o, 1).squeeze(0)\n",
    "x_tilde = flow_matching_conditional.sample(source, yd_o, only_last=False)\n",
    "\n",
    "x_tilde_scaled = rescale(x_tilde[:, -1, :], scales[\"x_mean\"], scales[\"x_std\"])\n",
    "source_scaled = rescale(x_tilde[:, 0, :], scales[\"x_mean\"], scales[\"x_std\"])\n",
    "\n",
    "# Convert tensors to DataFrames with labels\n",
    "df_samples = pd.DataFrame(x_tilde_scaled.numpy(), columns=[\"x\", \"y\"])\n",
    "df_samples[\"label\"] = \"Samples\"\n",
    "\n",
    "df_data = pd.DataFrame(xd_o_scaled.numpy(), columns=[\"x\", \"y\"])\n",
    "df_data[\"label\"] = \"Data\"\n",
    "\n",
    "# Combine all dataframes\n",
    "df_all = pd.concat([df_samples, df_data], ignore_index=True)\n",
    "# Use sns.jointplot\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "g = sns.jointplot(\n",
    "    data=df_all, x=\"x\", y=\"y\", hue=\"label\", kind=\"scatter\", marginal_kws={\"fill\": False}\n",
    ")\n",
    "g.figure.suptitle(\"Joint Scatter and Marginal Histograms\")\n",
    "plt.savefig(savedir / \"fm_on_x_cond.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2f96f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = yd_o[:4].repeat_interleave(1000, 0)\n",
    "obs = flow_matching_conditional.sample(torch.randn_like(observation), observation, only_last=True)\n",
    "obs_scaled = rescale(obs, scales[\"x_mean\"], scales[\"x_std\"])\n",
    "obs_scaled = obs_scaled.reshape(4, 1000, 2).transpose(1, 0)\n",
    "yd_o_scaled = rescale(yd_o, scales[\"y_mean\"], scales[\"y_std\"])\n",
    "gt_scaled = simulator.denoise_dist(yd_o_scaled[:4]).sample((1000,)).cpu()\n",
    "\n",
    "print(\"plotting obs\")\n",
    "obs_patch = Patch(\n",
    "    facecolor=sns.color_palette(\"Blues\", as_cmap=False)[2], alpha=0.5, label=r\"$x|y_{obs}$\"\n",
    ")\n",
    "gt_patch = Patch(\n",
    "    facecolor=sns.color_palette(\"Reds\", as_cmap=False)[2], alpha=0.5, label=\"Ground Truth\"\n",
    ")\n",
    "fmcpe_patch = Patch(\n",
    "    facecolor=sns.color_palette(\"Greens\", as_cmap=False)[2], alpha=0.5, label=\"FMPE\"\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for i in range(4):\n",
    "    row, col = divmod(i, 2)\n",
    "    ax = axes[row][col]\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    obs = obs_scaled[:, i, :].numpy()\n",
    "    gt = gt_scaled[:, i, :].numpy()\n",
    "    fmcpe = samples[:, i, :].numpy()\n",
    "\n",
    "    # plot the two KDEs (no label needed here)\n",
    "    sns.kdeplot(x=gt[:, 0], y=gt[:, 1], ax=ax, fill=True, cmap=\"Reds\", alpha=0.8)\n",
    "    sns.kdeplot(x=obs[:, 0], y=obs[:, 1], ax=ax, fill=True, cmap=\"Blues\", alpha=0.5)\n",
    "    # sns.kdeplot(x=fmcpe[:, 0], y=fmcpe[:, 1], ax=ax, fill=True, cmap=\"Greens\", alpha=0.5)\n",
    "    # sns.kdeplot(\n",
    "    #     x=xd_o_scaled[:, 0].numpy(),\n",
    "    #     y=xd_o_scaled[:, 1].numpy(),\n",
    "    #     ax=ax,\n",
    "    #     fill=False,\n",
    "    #     color=\"gray\",\n",
    "    #     alpha=0.5,\n",
    "    # )\n",
    "\n",
    "    ax.set_title(f\"Observation {i + 1}\")\n",
    "    ax.set_xlabel(r\"$\\mathbf{\\theta}_1$\")\n",
    "    ax.set_ylabel(r\"$\\mathbf{\\theta}_2$\")\n",
    "\n",
    "    # add the proxy legend\n",
    "    ax.legend(handles=[obs_patch, gt_patch], loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(savedir / \"fm_on_y_cond_obs.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmcpe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
